# Example domain configuration for demonstrating different model loading strategies
domain_id: model_loading_examples
description: "Demonstration of different model loading approaches"

endpoints:
  # Predict using HTTP model (existing approach)
  http_model:
    description: "Standard HTTP model endpoint"
    endpoint_type: "ml"
    data_sources:
      - name: prediction
        type: ml
        source_id: http_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
    response_mapping:
      model_type: "http"
      predictions: "$prediction"
  
  # Predict using local artifact model
  local_artifact_model:
    description: "Model loaded from local artifacts"
    endpoint_type: "ml"
    data_sources:
      - name: prediction
        type: ml
        source_id: local_artifact_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
    response_mapping:
      model_type: "local_artifact"
      predictions: "$prediction"
  
  # Predict using Docker model
  docker_model:
    description: "Model loaded from Docker image"
    endpoint_type: "ml"
    data_sources:
      - name: prediction
        type: ml
        source_id: docker_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
    response_mapping:
      model_type: "docker"
      predictions: "$prediction"
  
  # Predict using ECR model
  ecr_model:
    description: "Model loaded from ECR"
    endpoint_type: "ml"
    data_sources:
      - name: prediction
        type: ml
        source_id: ecr_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
    response_mapping:
      model_type: "ecr"
      predictions: "$prediction"
  
  # Compare multiple model predictions
  compare:
    description: "Compare predictions from different models"
    endpoint_type: "composite"
    data_sources:
      # Get predictions from all models
      - name: http_prediction
        type: ml
        source_id: http_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
      
      - name: local_prediction
        type: ml
        source_id: local_artifact_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
      
      - name: docker_prediction
        type: ml
        source_id: docker_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
      
      - name: ecr_prediction
        type: ml
        source_id: ecr_model
        operation: predict
        params:
          features:
            feature1: "$request.body.feature1"
            feature2: "$request.body.feature2"
    
    response_mapping:
      input_features:
        feature1: "$request.body.feature1"
        feature2: "$request.body.feature2"
      predictions:
        http_model: "$http_prediction"
        local_artifact_model: "$local_prediction"
        docker_model: "$docker_prediction"
        ecr_model: "$ecr_prediction"